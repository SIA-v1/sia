{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize image data generator with rescaling\n",
    "train_data_gen = ImageDataGenerator(rescale=1./255)\n",
    "validation_data_gen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28958 images belonging to 7 classes.\n",
      "Found 7308 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "#Preprocess all the test Images\n",
    "train_generator = train_data_gen.flow_from_directory(\n",
    "    'DATASETS/FER-2013/archive/train',\n",
    "    target_size = (48 , 48),\n",
    "    batch_size = 64,\n",
    "    color_mode = \"grayscale\",\n",
    "    class_mode = 'categorical'\n",
    ")\n",
    "\n",
    "#Preprocess all the train Images\n",
    "validation_generator = validation_data_gen.flow_from_directory(\n",
    "    'DATASETS/FER-2013/archive/test',\n",
    "    target_size = (48 , 48),\n",
    "    batch_size = 64,\n",
    "    color_mode = \"grayscale\",\n",
    "    class_mode = 'categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py:86: UserWarning: Argument `decay` is no longer supported and will be ignored.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Create Model structure\n",
    "emotion_model = Sequential()\n",
    "\n",
    "emotion_model.add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=((48, 48, 1))))\n",
    "emotion_model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "emotion_model.add(Dropout(0.25))\n",
    "\n",
    "emotion_model.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\n",
    "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "emotion_model.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\n",
    "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "emotion_model.add(Dropout(0.25))\n",
    "\n",
    "emotion_model.add(Flatten())\n",
    "emotion_model.add(Dense(1024, activation=\"relu\"))\n",
    "emotion_model.add(Dropout(0.5))\n",
    "emotion_model.add(Dense(7, activation=\"softmax\"))\n",
    "\n",
    "emotion_model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(learning_rate=0.001, decay=1e-6), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 262ms/step - accuracy: 0.2657 - loss: 1.7882 - val_accuracy: 0.4128 - val_loss: 1.4935\n",
      "Epoch 2/50\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160us/step - accuracy: 0.5156 - loss: 1.5044 - val_accuracy: 0.3333 - val_loss: 1.6718\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 250ms/step - accuracy: 0.4352 - loss: 1.4647 - val_accuracy: 0.5018 - val_loss: 1.2871\n",
      "Epoch 4/50\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137us/step - accuracy: 0.4375 - loss: 1.4394 - val_accuracy: 0.5000 - val_loss: 1.0835\n",
      "Epoch 5/50\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 216ms/step - accuracy: 0.5058 - loss: 1.2908 - val_accuracy: 0.5407 - val_loss: 1.1991\n",
      "Epoch 6/50\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141us/step - accuracy: 0.6250 - loss: 1.0559 - val_accuracy: 0.5833 - val_loss: 1.2582\n",
      "Epoch 7/50\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 254ms/step - accuracy: 0.5376 - loss: 1.2016 - val_accuracy: 0.5626 - val_loss: 1.1731\n",
      "Epoch 8/50\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161us/step - accuracy: 0.7031 - loss: 0.9868 - val_accuracy: 0.5833 - val_loss: 0.9487\n",
      "Epoch 9/50\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 251ms/step - accuracy: 0.5664 - loss: 1.1455 - val_accuracy: 0.5707 - val_loss: 1.1405\n",
      "Epoch 10/50\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115us/step - accuracy: 0.5000 - loss: 1.1921 - val_accuracy: 0.4167 - val_loss: 1.3748\n",
      "Epoch 11/50\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 229ms/step - accuracy: 0.5890 - loss: 1.0961 - val_accuracy: 0.5822 - val_loss: 1.0968\n",
      "Epoch 12/50\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104us/step - accuracy: 0.6094 - loss: 0.8906 - val_accuracy: 0.4167 - val_loss: 1.3518\n",
      "Epoch 13/50\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 226ms/step - accuracy: 0.6015 - loss: 1.0570 - val_accuracy: 0.5839 - val_loss: 1.1080\n",
      "Epoch 14/50\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110us/step - accuracy: 0.5625 - loss: 1.1720 - val_accuracy: 0.3333 - val_loss: 1.6283\n",
      "Epoch 15/50\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 229ms/step - accuracy: 0.6212 - loss: 1.0125 - val_accuracy: 0.5977 - val_loss: 1.0779\n",
      "Epoch 16/50\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115us/step - accuracy: 0.5781 - loss: 1.0360 - val_accuracy: 0.6667 - val_loss: 1.0395\n",
      "Epoch 17/50\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 249ms/step - accuracy: 0.6245 - loss: 0.9781 - val_accuracy: 0.6020 - val_loss: 1.0759\n",
      "Epoch 18/50\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118us/step - accuracy: 0.5781 - loss: 0.9405 - val_accuracy: 0.6667 - val_loss: 1.1392\n",
      "Epoch 19/50\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 233ms/step - accuracy: 0.6459 - loss: 0.9334 - val_accuracy: 0.6059 - val_loss: 1.0656\n",
      "Epoch 20/50\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116us/step - accuracy: 0.6250 - loss: 1.0081 - val_accuracy: 0.6667 - val_loss: 0.8710\n",
      "Epoch 21/50\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 242ms/step - accuracy: 0.6581 - loss: 0.9016 - val_accuracy: 0.6044 - val_loss: 1.0722\n",
      "Epoch 22/50\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105us/step - accuracy: 0.7031 - loss: 0.7473 - val_accuracy: 0.6667 - val_loss: 0.8289\n",
      "Epoch 23/50\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 234ms/step - accuracy: 0.6689 - loss: 0.8681 - val_accuracy: 0.6068 - val_loss: 1.0702\n",
      "Epoch 24/50\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121us/step - accuracy: 0.5938 - loss: 0.9546 - val_accuracy: 0.7500 - val_loss: 1.1192\n",
      "Epoch 25/50\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 244ms/step - accuracy: 0.6894 - loss: 0.8327 - val_accuracy: 0.6127 - val_loss: 1.0606\n",
      "Epoch 26/50\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145us/step - accuracy: 0.6250 - loss: 0.9948 - val_accuracy: 0.5833 - val_loss: 1.4716\n",
      "Epoch 27/50\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 255ms/step - accuracy: 0.7072 - loss: 0.7914 - val_accuracy: 0.6124 - val_loss: 1.0751\n",
      "Epoch 28/50\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140us/step - accuracy: 0.6562 - loss: 0.8951 - val_accuracy: 0.9167 - val_loss: 0.4643\n",
      "Epoch 29/50\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 251ms/step - accuracy: 0.7151 - loss: 0.7658 - val_accuracy: 0.6044 - val_loss: 1.0810\n",
      "Epoch 30/50\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172us/step - accuracy: 0.7500 - loss: 0.6881 - val_accuracy: 0.6667 - val_loss: 1.0479\n",
      "Epoch 31/50\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 264ms/step - accuracy: 0.7183 - loss: 0.7563 - val_accuracy: 0.6188 - val_loss: 1.0676\n",
      "Epoch 32/50\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109us/step - accuracy: 0.6719 - loss: 0.8736 - val_accuracy: 0.5833 - val_loss: 0.7969\n",
      "Epoch 33/50\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 253ms/step - accuracy: 0.7309 - loss: 0.7251 - val_accuracy: 0.6157 - val_loss: 1.0873\n",
      "Epoch 34/50\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100us/step - accuracy: 0.7344 - loss: 0.8202 - val_accuracy: 0.6667 - val_loss: 0.8618\n",
      "Epoch 35/50\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 252ms/step - accuracy: 0.7392 - loss: 0.7023 - val_accuracy: 0.6214 - val_loss: 1.0869\n",
      "Epoch 36/50\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140us/step - accuracy: 0.6719 - loss: 0.8747 - val_accuracy: 0.6667 - val_loss: 0.7810\n",
      "Epoch 37/50\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 258ms/step - accuracy: 0.7468 - loss: 0.6791 - val_accuracy: 0.6169 - val_loss: 1.0922\n",
      "Epoch 38/50\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117us/step - accuracy: 0.7344 - loss: 0.6011 - val_accuracy: 0.6667 - val_loss: 1.2385\n",
      "Epoch 39/50\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 269ms/step - accuracy: 0.7571 - loss: 0.6511 - val_accuracy: 0.6235 - val_loss: 1.0737\n",
      "Epoch 40/50\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142us/step - accuracy: 0.7500 - loss: 0.6574 - val_accuracy: 0.6667 - val_loss: 1.3447\n",
      "Epoch 41/50\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 250ms/step - accuracy: 0.7620 - loss: 0.6399 - val_accuracy: 0.6176 - val_loss: 1.1169\n",
      "Epoch 42/50\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106us/step - accuracy: 0.7344 - loss: 0.7336 - val_accuracy: 0.8333 - val_loss: 0.6700\n",
      "Epoch 43/50\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 251ms/step - accuracy: 0.7775 - loss: 0.6075 - val_accuracy: 0.6205 - val_loss: 1.1292\n",
      "Epoch 44/50\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193us/step - accuracy: 0.8125 - loss: 0.6048 - val_accuracy: 0.3333 - val_loss: 3.0931\n",
      "Epoch 45/50\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 246ms/step - accuracy: 0.7806 - loss: 0.5957 - val_accuracy: 0.6246 - val_loss: 1.1226\n",
      "Epoch 46/50\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114us/step - accuracy: 0.8906 - loss: 0.5206 - val_accuracy: 0.7500 - val_loss: 0.6868\n",
      "Epoch 47/50\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 249ms/step - accuracy: 0.7871 - loss: 0.5805 - val_accuracy: 0.6179 - val_loss: 1.1450\n",
      "Epoch 48/50\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109us/step - accuracy: 0.7188 - loss: 0.7805 - val_accuracy: 0.3333 - val_loss: 1.7688\n",
      "Epoch 49/50\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 245ms/step - accuracy: 0.7942 - loss: 0.5600 - val_accuracy: 0.6210 - val_loss: 1.1420\n",
      "Epoch 50/50\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106us/step - accuracy: 0.7656 - loss: 0.5809 - val_accuracy: 0.6667 - val_loss: 1.5741\n"
     ]
    }
   ],
   "source": [
    "# Train the neural network/model\n",
    "emotion_model_info= emotion_model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=28958 // 64,\n",
    "    epochs= 50,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=7308 // 64\n",
    ")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model stricture in json file\n",
    "\n",
    "model_json = emotion_model.to_json()\n",
    "with open(\"emotion_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "#save trained model weignt in .h5 file\n",
    "emotion_model.save_weights(\"emotion_model.weights.h5\")   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
